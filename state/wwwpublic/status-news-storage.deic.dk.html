<!DOCTYPE html>
<html>
    <head>
        <meta http-equiv="Content-Type" content="text/html;charset=utf-8"/>
        <title>
            DeiC Storage Status
        </title>
        <!-- site default style -->
        <link rel="stylesheet" type="text/css" href="/images/default.css" media="screen"/>

        <!-- site basic skin style -->
        <!--<link rel="stylesheet" type="text/css" href="/images/static-skin.css" media="screen"/>-->
        <link rel="stylesheet" type="text/css" href="/images/skin/deic-basic/core.css" media="screen"/>

        <!-- base page styles -->
        <link rel="stylesheet" type="text/css" href="/images/css/jquery-ui.css" media="screen"/>

        <!-- country-dropdown -->
        <link rel="stylesheet" type="text/css" href="/images/lib/country-dropdown/css/msdropdown/dd.css" />
        <link rel="stylesheet" type="text/css" href="/images/lib/country-dropdown/css/msdropdown/flags.css" />

        <!-- override with any site-specific styles -->
        <link rel="stylesheet" type="text/css" href="/images/site-custom.css"
              media="screen"/>

        <!-- site skin style -->
        <link rel="stylesheet" type="text/css" href="/images/skin/deic-basic/ui-theme.css" media="screen"/>
        <link rel="stylesheet" type="text/css" href="/images/skin/deic-basic/ui-theme.custom.css" media="screen"/>

        <link rel="icon" type="image/vnd.microsoft.icon"
              href="/images/skin/deic-basic/favicon.ico"/>

        <script type="text/javascript" src="/images/js/jquery.js"></script>
        <script type="text/javascript" src="/images/js/jquery-ui.js"></script>
        <script type="text/javascript" src="/assets/js/V2/ui-dynamic.js"></script>
        <script type="text/javascript" src="/images/lib/country-dropdown/js/msdropdown/jquery.dd.min.js"></script>
        <script type="text/javascript">
         var locale = extract_default_locale();
         /* Init supported languages to just english and extend based on lang select */
         var supported_languages = ['en'];
         var default_lang = supported_languages[0];
         var user_lang;

         $(document).ready(function() {
             /* Extend supported_languages with all entries from select elem */
             $("#langselect option").each(function() {
                 var option_val = $(this).val();
                 if (supported_languages.indexOf(option_val) < 0) {
                     supported_languages.push($(this).val());
                 }
             });
             console.log("found supported langs: "+supported_languages);
             if (locale && supported_languages.indexOf(locale) >= 0)  {
                 user_lang = locale;
             } else {
                 console.log(locale+" not supported - fall back to: "+default_lang);
                 user_lang = default_lang;
             }

             /* Init NEWS as foldable, with latest entry open and with individual heights */
             $(".news-accordion").accordion({
                 collapsible: true,
                 //active: false,
                 heightStyle: "content"
             });
             /* fix and reduce accordion spacing */
             $(".ui-accordion-header").css("padding-top", 0).css("padding-bottom", 0).css("margin", 0);
             $("#langselect").on('change', function() { 
                 var lang = $(this).val();
                 //alert("switch_language: "+lang);
                 switch_language(lang);
             }
             );

             console.log("switch to user lang: "+user_lang);
             $("#langselect").val(user_lang);
             switch_language(user_lang);
             $("#langselect").msDropdown();
         });
        </script>

    </head>
    <body class="staticpage">
        <div id="topspace">
        </div>
        <div id="toplogo" class="staticpage">
            <div id="toplogoleft" class="staticpage">
            </div>
            <div id="toplogocenter" class="staticpage">
                <img src="/images/skin/deic-basic/banner-logo.jpg" id="logoimagecenter"
                     class="staticpage" alt="site logo center"/>
                <span id="logotitle" class="staticpage">
                    University of Copenhagen - Electronic Research Data Archive
                </span>
            </div>
            <div id="toplogoright" class="staticpage">
            </div>
        </div>

        <div class="contentblock staticpage" id="nomenu">
            <div class="precontentwidgets">
                <!-- begin user supplied pre content widgets -->
                <!-- empty -->
                <!-- end user supplied pre content widgets -->
            </div>
            <div id="migheader">
            </div>
            <div class="staticpage" id="content">
                <div class="righttext langselect">
                    <!-- Please refer to /images/lib/country-dropdown/index.html for more choices -->
                    <select name="languages" id="langselect">
                        <option value='da' data-image="/images/lib/country-dropdown/images/msdropdown/icons/blank.gif" data-imagecss="flag dk" data-title="Denmark">Dansk</option>
                        <option value='en' data-image="/images/lib/country-dropdown/images/msdropdown/icons/blank.gif" data-imagecss="flag us" data-title="United States" selected="selected">English</option>
                    </select>
                </div>
                <div class="english i18n" lang="en">
                    <h1 class="staticpage">UCPH DeiC Storage Status and News</h1>

                    <h2 class="staticpage">Status</h2>
                    <!-- Use one of these templates for brief status messages -->

                    <p id="brief-status-english" class="brief-status icon_online iconspace leftpad icontext">
                        All systems and services are fully operational.
                    </p>
                    <!--
                         <p id="brief-status-english" class="brief-status icon_slack iconspace leftpad icontext">
                         All services except MODI are fully operational.
                         </p>
                         <p id="brief-status-english" class="brief-status icon_slack iconspace iconleftpad icontext">
                         We're developing the new UI on this site - some features may not work, yet.
                         </p>
                         <p id="brief-status-english" class="brief-status icon_offline iconspace leftpad icontext">
                         We've experienced problems with the backend storage lately - access may be limited for now.
                         </p>
                         <p class="icon_slack iconspace leftpad icontext">
                         There's a problem with the backend storage - we're investigating.
                         </p>
                         <p class="icon_offline iconspace leftpad icontext">
                         All systems are down for maintenance - they will be back soon.
                         </p>
                         <p class="icon_offline iconspace leftpad icontext">
                         All systems except seafile are down for maintenance - they will be back soon.
                         </p>
                         <p class="icon_offline iconspace leftpad icontext">
                         There's a problem with access to the backend storage - we're investigating.
                         </p>
                         <p class="icon_slack iconspace leftpad icontext">
                         All services except Jupyter are fully operational.
                         </p>
                         <p class="icon_slack iconspace leftpad icontext">
                         All services except SIF are fully operational.
                         </p>
                         <p class="icon_slack iconspace leftpad icontext">
                         Web login/access may currently be unstable for UCPH users.
                         </p>
                         <p class="icon_slack iconspace leftpad icontext">
                         Web login/access is currently unstable - we're investigating
                         </p>
                         <p class="icon_slack iconspace leftpad icontext">
                         All access is currently unstable - we're investigating
                         </p>
                         <p class="icon_slack iconspace leftpad icontext">
                         All services except Seafile are fully operational.
                         </p>
                    -->


                    <p>
                        Please use the link at the bottom to contact support in case you have
                        questions or encounter any problems.
                    </p>

                    <!-- NOTE: 
                         UI V3 extracts the entries with brief-announce class and displays the
                         ones with current time in between start_DATE and end_DATE classes in the
                         site status popup. DATE must be ISO 8601 format dates
                         (YYYY-MM-DDThh:mm:ss) with a literal 'T' separator like:
                         2020-01-13T13:37:00
                    -->

                    <h2 class="staticpage">Latest News</h2>
                    <div class="news-accordion">
                        <h4 class="staticpage brief-announce start_2020-03-13T08:00:00 end_2020-03-30T23:59:59 sys_ALL svc_ALL">2020/03/13 - 2020/03/30: Limited Staff on-site due to COVID-19 Precautions</h4>
                        <p>
                            Due to the general university policies in relation to the on-going
                            COVID-19 (Corona) virus precautions we will try to work from home as
                            much as possible. This might affect the response time for incidents that
                            require our presence in the data centers. We will still handle any
                            serious incidents the next business day, if not sooner.
                        </p>
                        <h4 class="staticpage brief-announce start_2020-03-10T17:00:00  end_2020-03-19T16:00:00 sys_DeiC Storage svc_ALL">2020/03/18: Planned DeiC Storage Maintenance</h4>
                        <p>
                            We have a number of pending system and minor feature updates on the DeiC Storage
                            frontend. The work will require full frontend restarts in relation to
                            the system updates and a little additional downtime to resize a core file
                            system. All DeiC Storage services except Seafile will be down for shorter or longer
                            periods. The work will commence on March 18th at about 17.00 and we
                            expect to finish within a couple of hours, but reserve until next
                            morning to be on the safe side. Updates will be announced here as usual.
                        </p>
                        <h4 class="staticpage brief-announce start_2020-02-10T00:00:00 end_2020-02-24T00:00:00 sys_SIF sys_DeiC Storage sys_IDMC svc_OpenID svc_Web">2020/02/21-23: Planned Major UCPH Maintenance Weekend</h4>
                        <p>
                            UCPH have announced 
                            <a href="https://kunet.ku.dk/newsroom/news/Pages/Major-service-window-at-UCPH-in-February.aspx">
                                plans for a major service window</a> from Friday February 21st in the
                            afternoon to Sunday February 23rd late in the evening.
                            DeiC Storage/IDMC/SIF is not directly affected and should remain fully
                            online. Yet, the UCPH OpenID login service may be unstable in that 
                            period, despite their redundancies. Thus, UCPH users  may experience
                            problems especially in relation to DeiC Storage/IDMC/SIF web login during that
                            time frame.
                        </p>
                        <h4 class="staticpage brief-announce start_2020-02-18T00:00:00 end_2020-02-20T00:00:00 sys_DeiC Storage sys_IDMC svc_MODI">2020/02/19: Jupyter MODI Outage</h4>
                        <p>
                            The MODI compute cluster resource at Jupyter went offline due to a
                            backend network file sysem failure. It has been resolved and MODI is back online.
                        </p>
                        <h4 class="staticpage brief-announce start_2020-01-16T00:00:00 end_2020-01-23T00:00:00 sys_SIF svc_ALL">2020/01/22: Planned SIF Maintenance</h4>
                        <p>
                            We completed the planned upgrade of both system and SIF software between 16.00 and 22.00.
                            All services are back to normal.
                        </p>
                        <h4 class="staticpage brief-announce start_2020-01-09T00:00:00 end_2020-01-18T00:00:00 sys_DeiC Storage svc_DAG svc_MODI">2020/01/09: DAG and MODI introduces user packages</h4>
                        <p>
                            We updated DAG and MODI, in addition it is possible on DAG to install user packages for our Python environment by installing via pip / pip3 install --user <package> (as well as via install.packages in R) to one's own home directory. This means that you can now avoid having to reinstall packages every time you start a new Notebook. However, it has the limitation that the package to be imported over the network will make it significantly slower than if packages are directly installed in our Notebook image.
                            </p>
                            <h4 class="staticpage brief-announce start_2019-11-30T00:00:00 end_2019-12-05T08:00:00 sys_DeiC Storage svc_ALL">2019/12/04: Planned DeiC Storage Maintenance</h4>
                            <p>
                                We migrated the DeiC Storage frontend to faster and bigger disks to improve
                                performance of various local operations. The migration commenced on
                                Wednesday December 4th at about 16.50 and meant that DeiC Storage with all
                                services were taken offline for a while. During the maintenance window
                                we also ran some pending DAG system updates. We finished the work
                                within a couple of hours and everything should be back to normal.
                            </p>
                            <h4 class="staticpage brief-announce start_2019-11-05T17:00:00 end_2019-11-11T08:00:00 sys_DeiC Storage svc_DAG">2019/11/09+10: Planned DAG Maintenance</h4>
                            <p>
                                We completed the planned update and general hardening of the DAG service
                                with a number of service restarts and general reconfiguration of each node.
                                For now 5 out of 7 nodes are back to normal service with 2 being restored 
                                before they are back to being operational.
                            </p>
                            <h4 class="staticpage">2019/11/07: Planned SIF Maintenance</h4>
                            <p>
                                We completed the planned upgrade of both system and SIF software with a
                                reboot and some shorter service restarts between 17.20 and 18.15. All
                                services are back to normal.
                            </p>
                            <h4 class="staticpage">2019/11/05: Planned DeiC Storage Maintenance</h4>
                            <p>
                                We completed the planned upgrade of both system and DeiC Storage software with a
                                reboot and some shorter service restarts between 17.25 and 18.10. All
                                services are back to normal.
                            </p>
                            <h4 class="staticpage">2019/09/24: Seafile Migration and Down Time</h4>
                            <p>
                                As proclaimed in the June 26th entry we've now migrated the DeiC Storage Seafile
                                service for better performance and scalability. We commenced with the
                                actual migration to the new stand-alone setup on Tuesday at 8 in the
                                morning and the data migration and database sychronization was not
                                complete until Wednesday morning. After additional verification and
                                testing the service was back online Wednesday at about 11.15. The
                                migration unfortunately means that we have to suspend the previous
                                integration with read access to Seafile data through the standard DeiC Storage
                                user home. For the moment we will preserve read-only access to a
                                snapshot of the data from <em>right before</em> the migration in the
                                usual virtual seafile_readonly folder in the DeiC Storage home folder for people using
                                Seafile. It is meant for emergency access to data in case anybody should
                                experience problems after the migration and we will eventually remove it.
                                After the migration we have enabled transparent proxying of Seafile
                                requests from the old address to the new one. So the service should
                                remain functional with the existing configuration, but it may yield
                                better performance to switch the client to use the new location
                                directly. There's more information about the new address and client
                                configuration available under the Seafile section on your DeiC Storage Settings
                                page. Please note that the transparent proxy does not seem to fully work for
                                mobile devices. So if file open/download consistently fails there it is
                                likely necessary to switch them over to the new Seafile address.
                            </p>
                            <h4 class="staticpage">2019/09/18: Planned SIF Maintenance to Allow External Users</h4>
                            <p>
                                For months and months we have worked on getting mainly the legal and of
                                course the technical infrastructure in place to allow external users on
                                SIF. Now it is finally ready to roll out and officially approved. 
                                Thus, it will become possible to invite external users into existing
                                projects on SIF whenever a formal collaboration with people outside UCPH
                                is in place.
                                The update requires at least SIF service restarts and in general some
                                SIF service downtime should be expected in that time frame.
                                We began the updates on Wednesday September 18th starting from 13 and
                                we originally expected to be done sometime before 18 o'clock. However,
                                it turned out that the updates took longer than expected so we did not
                                finish the actual upgrade until a bit after 22 o'clock. Today we
                                completed the remaining verification tasks so we consider everything
                                back in normal service.
                            </p>
                            <h4 class="staticpage">2019/08/10: Planned UCPH System Maintenance and DOI outages</h4>
                            <p>
                                UCPH IT has informed us about planned system maintenance work in multiple
                                areas this coming weekend (August 10th and 11th). It will render various
                                components involved in the DOI assignment which we expose for DeiC Storage
                                freeze archives unavailable in that time period, but the rest of DeiC Storage
                                should remain unaffected.
                            </p>
                            <h4 class="staticpage">2019/07/30: DAG/MODI outages</h4>
                            <p>
                                We lost all contact with the DAG and MODI compute nodes on Sunday
                                morning due to a brief general power outage. Our technicians got around to
                                investigate and got the main DAG hosts back online Monday afternoon and
                                MODI returned on Monday evening. The special DGX-1 GPGPU node on DAG
                                took somewhat longer to handle but it was back online on Tuesday afternoon.
                            </p>
                            <h4 class="staticpage">2019/07/22: Power Outage in the HPC center: DAG/MODI outages</h4>
                            <p>
                                The HPC Center was among the victims of the brief power outage or glitch
                                on multiple campus areas at about 11 this morning. The core services are
                                all on uninterruptible power supply (UPS) and weren't affected, but the
                                DAG and MODI compute nodes are not covered and needed a bit of work to
                                get back online. The affected services were all restored before 14.
                            </p>
                            <h4 class="staticpage">2019/07/05: Outage in the storage backend: additional service outages</h4>
                            <p>
                                There was some additional fallout after the hardware breakdown yesterday and all
                                services had to be taken offline again for a while this morning. We are
                                done replacing failing componens and the problems should be over. All
                                DeiC Storage/IDMC and SIF services are back online.
                            </p>
                            <h4 class="staticpage">2019/07/04: Outage in the storage backend: all services down!</h4>
                            <p>
                                We had a serious hardware breakdown in the storage backend and had to
                                take all systems offline for emergency maintenance until replacement equipment
                                was ready. All DeiC Storage/IDMC and SIF services were offline, but are now back online.
                            </p>
                            <h4 class="staticpage">2019/07/04: Warning about Planned SIF Maintenance and Downtime</h4>
                            <p>
                                We are physically moving the SIF frontend machine and need about an hour
                                of downtime. The work will commence on Thursday July 4th at 10 in the
                                morning and will temporarily remove access to  all SIF services. We
                                expect the task to be complete and all services back online within an
                                hour, i.e. sometime before 11. Update: the move took somewhat longer
                                due to some pending important system updates not behaving as well as
                                expected. We were done and back online at about 12:30.
                            </p>
                            <h4 class="staticpage">2019/07/01: Slow/Missing Access</h4>
                            <p>
                                We had an outage in the backend storage around noon affecting access to all
                                services. The problem should now be solved and everything back to normal. 
                            </p>
                            <h4 class="staticpage">2019/06/26: Seafile restructuring and warning about weaker integration</h4>
                            <p>
                                Due to a steady increase in load we're planning to migrate the DeiC Storage
                                Seafile service from running side-by-side with the other services on the
                                same frontend to instead run on a stand-alone frontend. That should
                                allow for better performance and significantly help scaling to keep up
                                with a growing number of concurrent users in the future. At the same
                                time it allows for a simpler and more robust backend storage than the
                                current one. The disadvantage of the dedicated frontend is that it
                                makes it much harder to preserve the current DeiC Storage Files integration with
                                transparent read-only access to your Seafile data through the
                                <em>seafile_readonly</em> folder. Alas, that appears to be a necessary
                                loss.<br/>
                                We expect to put the new Seafile structure into production some time in
                                August and therefore expect the DeiC Storage Files integration to be phased out
                                in the coming months.
                                At the moment it is unclear if we'll be able to provide a similar
                                integration in the future or if the Seafile service will in practice
                                remain an independent service.
                            </p>
                            <h4 class="staticpage">2019/05/29: UCPH Phishing Attack</h4>
                            <p>
                                UCPH and KUMail was the target of multiple
                                big <a href="https://it.ku.dk/driftinfo/">phishing attacks</a>
                                recently. Please take proper precautions if you got caught and
                                disclosed you login credentials. E.g. apart from of course changing your
                                UCPH password also remember to change any possibly affected passwords
                                you have set for your DeiC Storage SFTP/FTPS/WebDAVS and Seafile services. While
                                at it we also strongly recommend enabling 2-factor authentication for
                                your DeiC Storage logins by following the 2-Factor Auth wizard on your DeiC Storage
                                Settings page. You can either use one of the common authentictor apps or
                                the NetIQ app, which UCPH recently started promoting for various services.
                            </p>
                            <h4 class="staticpage">2019/05/14: Login and Access Issues</h4>
                            <p>
                                We experienced new login and access problems since before
                                noon today. This time it was apparently an issue where our web server
                                and our Jupyter instances ended up in a fight for resources and
                                significanlty limited the chances of ordinary web browser access. After
                                some clean up, tuning and service restarts things are running as
                                expected again.
                            </p>
                            <h4 class="staticpage">2019/05/10: Jupyter Outage</h4>
                            <p>
                                We had a power outage in the HPC center today and the Jupyter nodes went
                                offline as a result. DAG was back online a bit after noon and MODI
                                followed a little later.
                            </p>
                            <h4 class="staticpage">2019/04/23: Login and Access Issues Again</h4>
                            <p>
                                It looks like the UCPH OpenID issues have returned this morning. We've
                                contacted University IT about the issue and await a solution.
                                Since noon it seems to be back to normal but we're monitoring it. 
                            </p>
                            <h4 class="staticpage">2019/03/27: Login and Access Issues</h4>
                            <p>
                                This morning from about 10.30 UCPH users experienced various issues
                                with DeiC Storage web use. Every operation involving actual login or just login
                                session checks took a long time and some times so long that it resulted
                                in a page load timeout and various other page navigation errors.
                                We tracked it down to be a problem with the UCPH OpenID service, which
                                we rely on for UCPH login to DeiC Storage. University IT had a look and got it
                                back to normal. So everything should be fully functional again. 
                            </p>
                            <h4 class="staticpage">2019/02/06: SIF Efficient Data Access</h4>
                            <p>
                                Finally efficient file and folder access through WebDAVS and SFTP has
                                arrived for SIF. The services already used in DeiC Storage had to be extended to
                                include detailed logging of every single access and file operation. For
                                higher security we've added twofactor auth and made it mandatory on
                                SIF. Finally we implemented additional restrictions for the services on
                                SIF, so that users can only access a single project at a time and only
                                from a single IP address there. This is in line with the existing data
                                leak prevention mechanisms enforced for SIF web access.
                                Please note that on SIF therefore both services require a previous web
                                login with twofactor auth for additional security. Apart from that the
                                same features are available, so that users can use SIF as a network
                                drive with similar setup as for DeiC Storage. Please refer to Efficient Data
                                Access sections in the user guide from the 
                                <a href="http://sif.ku.dk">SIF front page</a> for additional information.
                            </p>
                            <h4 class="staticpage">2019/01/21: Planned Maintenance - Expected Downtime</h4>
                            <p>
                                We've completed the planned upgrade of the software stack on DeiC Storage and
                                IDMC frontends with some pending security and general bug fixes. The
                                work began at about 18 and included a reboot of the frontend. Thus all
                                services were affected with some minutes of outage.
                            </p>
                            <h4 class="staticpage">2019/01/17: Web Access/Login Downtime and subsequent fallouts</h4>
                            <p>
                                We experienced errors related to authentication and generel Web access between 13:00 and 15:00.
                                The initial fallout was due to errors in authenticating against KU's OpenID service.
                                After this had been resolved and the service had settled for a while, 
                                subsequent authenticated users via the OpenID service experienced request failures both in accessing DeiC Storage and the Jupyter service.
                                This was discovered being due to a flood of failed requests from re-authenticated users accessing previously created Jupyter servers.
                                This was resolved by reseting the old Jupyter servers. For now this has stabilized both DeiC Storage and Jupyter, however we will continue to monitor 
                                the situtation if subsequent failures should arise.
                            </p>
                            <h4 class="staticpage">2018/09/09: Import Share Links</h4>
                            <p>
                                By request from users we added a feature to allow easy import of data
                                from Share Links into your own DeiC Storage/IDMC folders. From your Files page
                                you can right click a folder and choose Share Link &gt; Import. Then
                                enter/paste the ID or URL of the Share Link and click Ok to proceed with
                                complete import of all shared data directly into the folder. In case
                                you only want to import a particular file or folder from the Share Link
                                you can replace the '*' in the Source Path field with your desired
                                target before you click Ok. In any case the effect is that you get your
                                own copy of the data directly in your chosen folder.
                            </p>
                            <h4 class="staticpage">2018/09/08: Planned Jupyter Maintenance - Expected Downtime</h4>
                            <p>
                                We've upgraded the Jupyter service at DeiC Storage/IDMC as planned this
                                weekend. It required some Jupyter downtime especially on Saturday and
                                additional shorter inavailability periods on Sunday. All other services
                                ran unaffected. The maintenance was finished at 00:10 on the 10th of
                                September yielding a new clustered setup of 6 physical hosts delivering
                                the Jupyter service. Beyond that the systems were updated and configured
                                to allow for up to 8 cores and 8 GB of memory available to the individual
                                notebooks, while always providing at least 1 core and 1 GB of memory
                                even during congested periods. Everything at this point looks good and
                                we expect normal Jupyter operation - only now with better scalability.
                            </p>
                            <h4 class="staticpage">2018/09/03: Planned Maintenance - Expected Downtime</h4>
                            <p>
                                We've upgraded the backend storage software with some bug fixes and
                                prepared to add more disk space. The work began at 13 and resulted in
                                general service outages until about 14 due to low level
                                upgrades. Everything should be back to normal for DeiC Storage/IDMC. On SIF we
                                ran into some problems with the host which required additional work, but
                                it is also back online now.
                            </p>
                            <h4 class="staticpage">2018/07/18: Jupyter back online</h4>
                            <p>
                                The Jupyter upgrades on Friday turned out to be more work than expected
                                and required some more work this week. It is complete now and the
                                service is back online.
                            </p>
                            <h4 class="staticpage">2018/07/12: Jupyter maintenance and downtime</h4>
                            <p>
                                The Jupyter service will be partially or completely unavailable for the
                                rest of the day due to maintenance work and upgrades.<br/>
                            </p>
                            <h4 class="staticpage">2018/07/06: 2-Factor Authentication Support</h4>
                            <p>
                                In line with the recent IO-service security enhancements we've added
                                support for 2-factor authentication (2FA) in our OpenID web logins. This
                                means that users can now add an extra layer of security and make abuse
                                much harder - even if somebody should intercept their UCPH login and
                                password (or their dedicated DeiC Storage OpenID password in case of external
                                users). In short you as a security-minded user install an app on your
                                mobile device (smart-phone or tablet) and scan a personal QR security
                                code, which allows the app to continuously provide you with one-time
                                passcodes for use along with your usual login. This assures that one can
                                <em>only</em> get access by both knowing the password and possessing the
                                device. Further details about the setup and use of 2FA is available
                                under DeiC Storage Setttings -> Web Access.<br/>
                                We particularly recommend enabling 2FA if you use DeiC Storage for any data
                                categorized as confidentiality level F2 in the official UCPH data
                                classification available at the 
                                <a href="https://intranet.ku.dk/employeeguide/safety-and-emergency/information-security/Pages/default.aspx">
                                    UCPH intranet</a> (requires login).
                                It should be emphasized that data confidentiality level F1 is <em>not</em>
                                allowed on DeiC Storage and should instead use an even safer and more closely
                                monitored solution like e.g. <a href="http://sif-www.storage.deic.dk">SIF</a>.<br/>
                                We are currently investigating the possibilities for similar 2FA support
                                on the IO-services.
                            </p> 
                            <h4 class="staticpage">2018/06/25: Password tightening on WebDAVS/SFTP/FTPS</h4>
                            <p>
                                Due to a rise in the number of automated password guessing attempts
                                we've chosen to strengthen the password requirements for our services
                                with password-login. This means that since yesterday we enforce not only
                                the standard UCPH password requirements of eight characters from at least
                                three character classes but also a number of additional checks for
                                dictionary words and simple patterns.<br/>
                                The rules were immediately enforced when setting or changing password
                                and will also be enforced for existing passwords next time we restart
                                the services.<br/>
                                In case you can no longer access DeiC Storage through WebDAVS/SFTP/FTPS, please
                                go to your DeiC Storage Settings page and try to set the password again for the
                                particular service. If it is refused you need to come up with a new
                                stronger password.
                            </p> 
                            <h4 class="staticpage">2018/06/21: Rate limit SFTP logins</h4>
                            <p>
                                Due to a rise in the number of automated password guessing attempts
                                we've implemented further rate limits on apparent attackers at our
                                SFTP service. This means that too many failed login attempts result in
                                automatic temporary banning of the IP address for a while. Please
                                contact us if you run into problems with your connections and transfers.
                            </p> 
                            <h4 class="staticpage">2018/06/20: Planned Maintenance - Expected Downtime</h4>
                            <p>
                                We've upgraded the backend storage software to a more recent version in
                                order to apply a number of bug fixes. This should include stability
                                fixes related to the occasional connection losses we've seen during the
                                last year. The work began at 9 and all systems were offline until we
                                finished the upgrade at about 12:30. Everything looks good so far and we
                                expect things to be back to normal now.
                            </p> 
                            <h4 class="staticpage">2018/06/18: Short inaccessibility</h4>
                            <p>
                                We had a hiccup on the frontend this morning and had to restart all
                                services. While at it we forced a pending reboot. Everything should be
                                back to normal again. 
                            </p> 
                            <h4 class="staticpage">2018/06/13: New DOI Integration</h4>
                            <p>
                                University IT has put their new Digital Object Identifier (DOI)
                                registration service in production and we have integrated it with DeiC Storage
                                freeze archives. This means that it is now possible to get a short and
                                permanent DOI reference to DeiC Storage archive data - something a number of
                                organizers and funders have started to require when publishing research
                                results.
                            </p> 
                            <h4 class="staticpage">2018/04/19: Partial Data Access and Seafile down</h4>
                            <p>
                                We've seen additional connection losses to the backend storage servers
                                and had to restart services to recover. Seafile required extra
                                maintenance, which should be resolved now.
                            </p> 
                            <h4 class="staticpage">2018/04/17: Partial Data Access</h4>
                            <p>
                                We lost the connection to one or more backend storage servers and
                                the result was limited data access in all services.<br/>
                                Everything is back online and we're closely monitoring the systems.<br/>
                                Additionally we're planning an upgrade to the glusterfs software
                                providing the link to the backend storage. It should address a number of
                                issues related to the problems we've seen lately with connection loss.
                            </p>
                            <h4 class="staticpage">2018/04/06: Enabling Workgroup Workflows again</h4>
                            <p>
                                We have optimized our Workgroup Workflows service to be far less taxing
                                on the system and thus we have enabled it in production again.
                            </p>
                            <h4 class="staticpage">2018/03/16: Partial Data Access and Login Problems</h4>
                            <p>
                                We had a CPU-lockup on one of our backend storage servers.<br/>
                                Everything is back online and we're closely monitoring the systems.<br/>
                            </p>
                            <h4 class="staticpage">2018/03/15: Temporarily Disabling Workgroup Workflows</h4>
                            <p>
                                We have a hunch that our Workgroup Workflows service had a negative
                                impact on the problems we saw recently after the disk failure and
                                replacement. Therefore we have chosen to temporarily disable it at
                                DeiC Storage. In case you were using it for automated backup as described in
                                the user guide, you can either switch it over to the new Schedule Tasks
                                service or contact us for a temporary replacement. Our plan is to enable
                                workflows again once we have optimized the service to be significantly
                                less resource intensive.
                            </p>
                            <h4 class="staticpage">2018/03/12: Partial Data Access and Login Problems</h4>
                            <p>
                                We had a disk crash last night and needed a physical replacement. As a
                                result we only had partial data visibility, meaning that some files
                                would appear missing even though they were actually intact. For some
                                users this happened to be important login files, in effect preventing log
                                in. We solved the disk problems but had a few hiccups with lost
                                connections to the backend storage throughout the day. Each time the 
                                result was similar partial visibility and login problems for some
                                users.<br/>
                                Everything is back online and we're closely monitoring the systems.<br/>
                            </p>
                            <h4 class="staticpage">2018/03/11: Data Access Problems</h4>
                            <p>
                                The issues from a week ago re-appeared and we had to manually intervene
                                to get everything back online. This resulted in partial data access and
                                some temporary service outages.
                            </p>
                            <h4 class="staticpage">2018/03/05: Schedule Tasks Feature in Beta</h4>
                            <p>
                                We have enabled a new feature to schedule tasks in beta test at DeiC Storage. It
                                can be used to automate tasks at given times, running on behalf of
                                you. One such task would be the creation of backup archives e.g. every
                                night. Further details about use and possibilities are available in the
                                user guide.
                            </p>
                            <h4 class="staticpage">2018/03/04: Data Access Errors and a Restart</h4>
                            <p>
                                We experienced connection issues between the frontend and backend
                                storage resulting in e.g. directory removals failing. We had to
                                re-establish the backend connection and restart all services to solve
                                the problems, and everything should be back to normal again.
                            </p>
                            <h4 class="staticpage">2018/02/21: Seafile Upgrade</h4>
                            <p>
                                We upgraded our Seafile installation to receive a number of bug fixes
                                including one reported by some of you (thanks!). Namely that the Seafile web
                                interface consistently failed to display files with either space or
                                exotic characters in their file name or full path. Everything should be
                                back online again after the upgrade and service restart. 
                            </p>
                            <h4 class="staticpage">2018/02/13: High-performance SFTP Service in General Use</h4>
                            <p>
                                After some months in beta test at sftp.storage.deic.dk we've enabled our new
                                high-performance SFTP service on the standard io.storage.deic.dk address. We've
                                measured speedups ranging from 10 to 32 times for transfers on a fast
                                network link to DeiC Storage. Even on slower networks you are likely to see
                                improvements.
                            </p>
                            <h4 class="staticpage">2018/02/12: Slow-down / Service Outages</h4>
                            <p>
                                All services were extremely slow this morning due to a disk issue on
                                the frontend node. In some cases it resulted in connections timing
                                out. The problem is solved and everything should be back to normal again.<br/>
                                In the afternoon it turned out that Seafile did not like the
                                aforementioned outage and needed a bit of additional cleaning up to run
                                properly. It is back to normal now.
                            </p>
                            <h4 class="staticpage">2018/01/25: Maintenance and Brief Service Outage</h4>
                            <p>
                                All services were briefly down for scheduled software updates. These
                                included a number of minor bugfixes plus optimizations in relation to
                                not wasting resources on automated attacks from the Internet - such as
                                password guessing attempts. Everything should be back to normal again. 
                            </p>
                            <h4 class="staticpage">2018/01/10: Important Security Upgrades</h4>
                            <p>
                                We finished applying a set of urgent security updates in relation to the
                                <a href="https://meltdownattack.com/">Meltdown and Spectre</a> security
                                issues. This involved a reboot for kernel updates and thus a resulting
                                brief general outage for all services.
                            </p>
                            <h4 class="staticpage">2018/01/10: Partial data visibility</h4>
                            <p>
                                Our active frontend node lost sight of a number of files on the backend
                                storage nodes. This in particular resulted in one or more workgroup folders
                                not showing up in the user file space. No data was lost and a reload of
                                the storage connection fixed the problem.
                            </p>
                            <h4 class="staticpage">2017/11/02: System Outage and Seafile Data Loss</h4>
                            <p>
                                We experienced a massive system outage due to a disk and a CPU failing
                                hard in turn. This left part of our systems offline for most of a day
                                until we had restored and migrated the tasks to another host. On the
                                good side ordinary DeiC Storage data was not permanently affected by the outage
                                which can be seen as marker of the robustness of our general
                                infrastructure. On the bad side we've received reports of some DeiC Storage
                                Seafile users getting one or more files rolled back to a previous
                                version effectively overwriting any recent changes. We are of course
                                sorry for any inconvenience this has caused and we have done our best to
                                help trace down the underlying problem. 
                                We would also like to emphasize that Seafile is a third party service we
                                only host on DeiC Storage due to popular demand. Thus, it follows the same backup
                                policies, meaning that <em>you</em> as a user are responsible for explicitly
                                making backups. You may use e.g. our Archive feature which copies data to
                                off-site tape for strong protection against any such data loss.
                            </p>
                            <h4 class="staticpage">2017/09/21: High-performance SFTP Service in Beta</h4>
                            <p>
                                Our new high-performance SFTP service is now available on sftp.storage.deic.dk
                                with the same login procedure as the existing one on io.storage.deic.dk. You can
                                try it out as a drop-in replacement using the same procedure just
                                replacing the address. We've measured speedups ranging from 10 to 32
                                times for transfers on a fast network link to DeiC Storage. Even on slower
                                networks you are likely to see improvements.
                            </p>
                            <h4 class="staticpage">2017/07/25: OpenID Login for Users without a UCPH Account</h4>
                            <p>
                                We've added another access method to allow people without a general
                                KU/UCPH account to use DeiC Storage with simple username and password
                                login. This new service makes it a lot simpler for e.g. external
                                collaboration partners to sign up and use DeiC Storage. Please refer to our <a href="http://www.storage.deic.dk/index.html">FAQ</a>
                                entry on the subject for the details.
                            </p>
                            <h4 class="staticpage">2017/04/21: Write-restricted Workgroup Shared Folders</h4>
                            <p>
                                The workgroup infrastructure was changed to allow the associated shared
                                folders to be write-protected by owners. In effect this allows easy
                                sharing of data in a read-only fashion inside workgroups. All workgroups
                                will still have their shared folder in read/write mode by default but owners
                                can switch all new workgroups to read-only from the workgroup
                                administration page. It should be noted that all workgroups created
                                before this date will need to be migrated first if they are to provide the same
                                feature. Please contact support about such inquiries.
                            </p>
                    </div>
                    <p>
                        <a href="http://www.storage.deic.dk">Return to main page</a>
                    </p>
                </div>
                <div class="danish i18n" lang="da">
                    <h1 class="staticpage">UCPH DeiC Storage status og nyheder</h1>

                    <h2 class="staticpage">Status</h2>
                    <!-- Use one of these templates for brief status messages -->
                    <p id="brief-status-danish" class="brief-status icon_online iconspace leftpad icontext">
                        Alle systemer og services kører planmæssigt.
                    </p>
                    <!--
                         <p id="brief-status-danish" class="brief-status icon_slack iconspace leftpad icontext">
                         Alle services undtagen MODI kører planmæssigt.
                         </p>
                         <p class="icon_slack iconspace leftpad icontext">
                         Vi har på det sidste oplevet problemer med backend-lageret - begrænset adgang kan forekomme.
                         </p>
                         <p class="icon_slack iconspace leftpad icontext">
                         Der er i øjeblikket udfald i backend-lageret - vi undersøger sagen.
                         </p>
                         <p class="icon_slack iconspace leftpad icontext">
                         Alle services undtagen Seafile kører planmæssigt.
                         </p>
                         <p class="icon_offline iconspace leftpad icontext">
                         Alle systemer er i øjeblikket nede p.g.a. planlagt vedligehold.
                         </p>
                         <p class="icon_offline iconspace leftpad icontext">
                         Alle systemer bortset fra seafile er i øjeblikket nede p.g.a. planlagt vedligehold.
                         </p>
                         <p class="icon_offline iconspace leftpad icontext">
                         Der er i øjeblikket problemer med adgang til backend-lageret - vi undersøger sagen.
                         </p>
                         <p class="icon_slack iconspace leftpad icontext">
                         Der er i øjeblikket problemer med backend-lageret - vi undersøger sagen.
                         </p>
                         <p class="icon_slack iconspace leftpad icontext">
                         Alle services undtagen Jupyter kører planmæssigt.
                         </p>
                         <p class="icon_slack iconspace leftpad icontext">
                         Alle services undtagen SIF kører planmæssigt.
                         </p>
                         <p class="icon_slack iconspace leftpad icontext">
                         Der kan i øjeblikket være problemer med weblogin/-adgang for KU-brugere.
                         </p>
                         <p class="icon_slack iconspace leftpad icontext">
                         Der er i øjeblikket problemer med weblogin/-adgang - vi undersøger sagen
                         </p>
                         <p class="icon_slack iconspace leftpad icontext">
                         Der er i øjeblikket problemer med al adgang - vi undersøger sagen
                         </p>
                         <p class="icon_slack iconspace leftpad icontext">
                         Alle services undtagen Seafile kører planmæssigt.
                         </p>
                    -->

                    <p>
                        Benyt venligst linket nederst på siden til at kontakte support såfremt
                        du har spørgsmål eller oplever problemer.
                    </p>

                    <h2 class="staticpage">Seneste nyt</h2>
                    <div class="news-accordion">
                        <h4 class="staticpage brief-announce start_2020-03-13T08:00:00 end_2020-03-30T23:59:59 sys_ALL svc_ALL">13/03-2020 - 30/03-2020: Nedsat lokal bemanding grundet COVID-19 forholdsregler</h4>
                        <p>
                            På grund af universitetets generelle politik om begrænset fysisk adgang
                            under den igangværende COVID-19 (Corona) virus-trussel, arbejder vi mest
                            muligt hjemmefra. Det kan få indflydelse på responstiderne i tilfælde af
                            fejl eller udfald som kræver fysisk tilstedeværelse i
                            datacentrene. Alvorlige problemer vil fortsat behandles næste
                            arbejdsdag, hvis ikke før.
                        </p>
                        <h4 class="staticpage brief-announce start_2020-03-10T17:00:00
                                   end_2020-03-19T16:00:00 sys_DeiC Storage svc_ALL">18/03-2020: Planlagt vedligehold på DeiC Storage</h4>
                        <p>
                            Vi har et antal udestående system- og nogle mindre funktionelle opdateringer
                            på DeiC Storages frontend. Arbejdet kræver genstart af hele frontend ifm
                            systemopdateringerne og desuden lidt nedetid til at forstørre et centralt
                            filsystem. Alle DeiC Storage services bortset fra Seafile vil være nede i
                            kortere eller længere perioder under opdateringen. Arbejdet begynder den
                            18. marts omkring kl 17.00 og vi forventer at være færdige på et par
                            timer, men holder for en sikkerheds skyld bagkanten åben for at forlænge
                            til næste morgen. Statusopdateringer følger som altid her.
                        </p>
                        <h4 class="staticpage brief-announce start_2020-02-10T00:00:00
	                           end_2020-02-24T00:00:00 sys_SIF sys_DeiC Storage sys_IDMC svc_OpenID
	                           svc_Web">21-23/02-2020: Planlagt Stort KU Servicevindue</h4>
                        <p>
                            KU har udmeldt 
                            <a href="https://kunet.ku.dk/nyhedsrum/nyheder/Sider/Servicevindue-p%C3%A5-KU.aspx">
                                planer om et stort servicevindue</a> fra fredag den 21. februar om
                            eftermiddagen til søndag den 23. februar sent om aftenen.
                            DeiC Storage/IDMC/SIF er ikke direkte berørt og skulle forblive online. Ikke
                            desto mindre vil arbejdet berøre KU OpenID login-servicen, som vi
                            benytter. Så det kan ikke udelukkes at den del vil være ustabil i
                            perioden. D.v.s. KU-brugere vil muligvis opleve problemer især omkring
                            login på DeiC Storage/IDMC/SIF web i det givne tidsrum.
                        </p>
                        <h4 class="staticpage brief-announce start_2020-02-18T00:00:00 end_2020-02-20T00:00:00 sys_DeiC Storage sys_IDMC
                                   svc_MODI">19/02-2020: Jupyter MODI udfald</h4>
                        <p>
                            MODI klyngeresursen på Jupyter var nede pga en fejl i dens
                            netværksfilsystem. Vi har fået løst problemet og MODI er tilbage i drift. 
                        </p>
                        <h4 class="staticpage brief-announce start_2020-01-16T00:00:00 end_2020-01-23T00:00:00 sys_SIF svc_ALL">22/01-2020: Planlagt SIF systemvedligehold</h4>
                        <p>
                            Vi har overstået den varslede opdatering af både system og SIF software 
                            imellem 16.00 og 22.00. Alle services kører igen normalt. 
                        </p>
                        <h4 class="staticpage brief-announce start_2020-01-09T00:00:00 end_2020-01-18T00:00:00 sys_DeiC Storage svc_DAG svc_MODI">09/01-2020: DAG og MODI introducerer brugerspecifikke pakker</h4>
                        <p>
                            Vi opdaterede DAG og MODI, herefter er det muligt på DAG at installere user pakker til 
                            vores Python miljø ved at installere via pip/pip3 install --user <package> (samt via install.packages i R)
                            til ens eget hjemme bibliotek. Dette gør at man nu kan slippe for at skulle geninstallere 
                            pakker hver gang man starter en ny Notebook. Dog har det den begrænsning at pakken skal 
                            importeres over netværket hvilket vil gøre det væsentlig langsommere end 
                            hvis pakker er direkte installeret i vores Notebook image.
                            </p>
                            <h4 class="staticpage brief-announce start_2019-11-30T00:00:00 end_2019-12-05T08:00:00 sys_DeiC Storage svc_ALL">04/12-2019: Planlagt DeiC Storage systemarbejde</h4>
                            <p>
                                Vi migrerede DeiC Storages frontend til større og hurtigere diske for at forbedre
                                ydelsen på forskellige lokale operationer. Migreringsarbejdet begyndte onsdag den
                                4. december omkring kl 16.50 og betød at DeiC Storage med alle services var
                                utilgængelig i et stykke tid. I samme forbindelse foretog vi nogle
                                udestående systemopdateringer på DAG. Vi færdiggjorde arbejdet i
                                løber af et par timer og alt skulle være tilbage i normal drift.
                            </p>
                            <h4 class="staticpage brief-announce start_2019-11-05T17:00:00 end_2019-11-11T08:00:00 sys_DeiC Storage svc_DAG">09+10/11-2019: Planlagt DAG vedligeholdelse</h4>
                            <p>
                                Vi afsluttede den planlagte opdatering og generelle hærdning af DAG-tjenesten
                                med et antal servicegenstarter og generel rekonfiguration af hver knude.
                                I øjeblikket er 5 ud af 7 noder tilbage til normal service, hvor 2 er under
                                gendannelse før de er tilbage til at være operationelle.
                            </p>
                            <h4 class="staticpage">07/11-2019: Planlagt SIF systemvedligehold</h4>
                            <p>
                                Vi har overstået den varslede opdatering af både system og SIF software med
                                en genstart og nogle korte udfald mellem 17.20 og 18.15. Alle services
                                kører igen normalt. 
                            </p>
                            <h4 class="staticpage">05/11-2019: Planlagt DeiC Storage systemvedligehold</h4>
                            <p>
                                Vi har overstået den varslede opdatering af både system og DeiC Storage software med
                                en genstart og nogle korte udfald mellem 17.25 og 18.10. Alle services
                                kører igen normalt. 
                            </p>
                            <h4 class="staticpage">24/09-2019: Seafile migrering og nedetid</h4>
                            <p>
                                Som varslet den 26/6 har vi migreret DeiC Storage Seafile-servicen med henblik
                                på at forbedre dens ydelse og skalering. Vi gik igang med den endelige
                                migrering tirsdag kl 8 og datamigreringen og efterfølgende
                                databasesynkroniserig var først færdig onsdag morgen. Efter yderligere
                                kontrol og test var servicen tilbage i drift onsdag omkring kl 11.15.
                                Migreringen betyder at vi på ubestemt tid må suspendere den hidtidige
                                integration med læseadgang til ens Seafile data fra den almindelige DeiC Storage
                                brugermappe. Vi beholder dog for nu læseadgang til et snapshot af data
                                <em>umiddelbart inden</em> migreringen via den virtuelle seafile_readonly
                                mappe i DeiC Storage brugermappen for Seafile-brugere. Den kan benyttes som
                                nødløsning hvis nogen skulle opleve problemer efter migreringen, og vi
                                fjerner den på sigt.
                                Efter migreringen har vi opsat gennemsigtig viderestilling af
                                Seafile-forespørgsler fra den gamle til den nye adresse. Servicen skulle
                                således gerne forblive funktionel med eksisterende konfigurationer, men
                                det vil formodentlig give bedre ydelse at skifte over til den nye
                                placering direkte. Yderligere detaljer om den nye adresse og
                                klient-opsætning findes under Seafile på ens DeiC Storage Settings side. Bemærk
                                at den gennemsigtige viderestilling tilsyneladende ikke virker fuldt ud
                                på mobile enheder, så hvis vis/hent fil fejler der, er det
                                sandsynligvis nødvendigt at skifte dem over til den nye Seafile-adresse.
                            </p>
                            <h4 class="staticpage">18/09-2019: Planlagt SIF systemvedligehold mhp at tillade eksterne brugere</h4>
                            <p>
                                I adskillige måneder har vi arbejdet på at få organiseret især de
                                juridiske men også tekniske procedurer for at kunne give eksterne
                                brugere adgang til SIF. Nu er det endelig klar og officielt godkendt til
                                at blive sat i drift. 
                                Det bliver derved muligt at invitere eksterne brugere ind i eksisterende
                                projekter på SIF, når der foreligger et formelt samarbejde med folk
                                udenfor KU.
                                I forbindelse med opdateringern er det nødvendigt som minimum at
                                genstarte alle SIF services og generelt må der forventes kortere eller
                                længere SIF nedetid undervejs.
                                Vi begyndte opdateringerne onsdag den 18. september fra kl. 13 og vi
                                forventede oprindeligt at arbejdet ville være overstået inden kl 18. Det
                                viste sig dog mere omfattende end ventet, så vi var først færdige med
                                selve opdateringen lidt efter kl. 22. I dag har vi kørt de resterende
                                verificeringsopgaver og alting er igen at betragte som i normal drift. 
                            </p>
                            <h4 class="staticpage">10/08-2019: Planlagt KU systemvedligehold og DOI utilgængelighed</h4>
                            <p>
                                KU IT melder om planlagt systemvedligehold i den kommende weekend
                                (10. og 11. august). Et antal komponenter involveret i den DOI-tildeling
                                vi eksponerer for DeiC Storage freeze archives vil derfor ikke være tilgængelige
                                i den periode, men resten af DeiC Storage skulle forblive i normal drift.
                            </p>
                            <h4 class="staticpage">30/07-2019: DAG og MODI nede</h4>
                            <p>
                                Vi mistede al kontakt til maskinerne på DAG og MODI søndag formiddag pga
                                et omfattende strømudfald. Vores teknikere undersøgte sagen nærmere og fik de
                                almindelige DAG maskiner tilbage i drift mandag eftermiddag og MODI kom
                                tilbage mandag aften. Den specielle DGX-1 GPGPU maskine på DAG tog noget
                                længere at håndtere, men den var tilbage i almindelig drift tirsdag
                                eftermiddag.
                            </p>
                            <h4 class="staticpage">22/07-2019: Strømsvigt i HPC Centeret: DAG og MODI nede</h4>
                            <p>
                                HPC Centeret var blandt de ramte i strømudfaldet på flere dele af campus
                                omkring kl 11 i formiddags. Alt centralt udstyr og services er på
                                nødstrøm (UPS) og blev derfor ikke berørt. Beregningsmaskinerne i DAG og
                                MODI er ikke dækket og krævede lidt arbejde at få tilbage i drift efter
                                udfaldet. De berørte systemer var tilbage i normal drift inden kl 14.
                            </p>
                            <h4 class="staticpage">05/07-2019: Udfald i backend-lageret: efter-veer og udfald</h4>
                            <p>
                                Der var opstod nogle følgeproblemer af gårsdagens hardwarenedbrud og det
                                førte til yderligere et udfald i morges. Vi er færdige med at udskifte
                                de problematiske komponenter og problemerne skulle være løst. Alle
                                DeiC Storage/IDMC og SIF services er tilbage i almindelig drift.
                            </p>
                            <h4 class="staticpage">04/07-2019: Udfald i backend-lageret: alt offine!</h4>
                            <p>
                                Vi havde et større hardwarenedbrud i backend-lageret til
                                eftermiddag/aften og alt måtte tages offline indtil vi havde nyt
                                maskinel kørt i stilling. Alle DeiC Storage/IDMC og SIF services var nede, men
                                er nu tilbage online.
                            </p>
                            <h4 class="staticpage">04/07-2019: Varsel om planlagt systemarbejde og nedetid på SIF</h4>
                            <p>
                                Vi flytter SIF frontend-maskinen og har i den forbindelse brug for
                                omkring en times nedetid. Arbejdet vil starte på torsdag den 4. juli kl
                                10 om formiddagen og vil midlertidigt gøre alle SIFs services
                                utilgængelige. Vi forventer at arbejdet er overstået i løbet af en time
                                og alt således er tilbage i normal drift inden kl 11. Opdatering:
                                arbejdet blev forsinket af at nogle vigtige systemopdateringer ikke
                                opførte sig helt så pænt som ventet. Vi var færdige og tilbage online
                                omkring kl 12:30.
                            </p>
                            <h4 class="staticpage">01/07-2019: Begrænset/ingen adgang</h4>
                            <p>
                                Vi havde et udfald i backend-lageret omkring middag og det berørte alle
                                services. Problemet skulle nu være løst og alt tilbage i almindelig drift.
                            </p>
                            <h4 class="staticpage">26/06-2019: Seafile omstrukturering og varsel om nedsat integration</h4>
                            <p>
                                Grundet støt stigende belastning planlægger vi at omlægge DeiC Storage Seafile
                                servicen fra at køre på samme frontend som de andre DeiC Storage services til i
                                stedet at køre på sin egen dedikerede frontend. Det skulle give bedre
                                ydelse samt markant bedre mulighed for at kunne skalere til også at
                                kunne håndtere det stigende antal samtidige brugere i
                                fremtiden. Desuden giver det mulighed for at bruge et simplere og mere
                                robust backend-lager end det nuværende. Ulempen ved den udskilning er at
                                vi så ikke længere uden videre kan tilbyde den nuværende tætte
                                integration i DeiC Storage Files med sømløs skrivebeskyttet adgang til ens
                                Seafile data via <em>seafile_readonly</em> mappen. Det lader desværre
                                til at være et nødvendigt offer.<br/>
                                Vi forventer at den nye struktur vil komme i drift i løbet af august og
                                at integrationen i DeiC Storage Files derfor vil udfases i løbet af de kommende
                                måneder. Det er på nuværende tidspunkt uvist om vi på sigt igen vil
                                kunne tilbyde en sådan funktionalitet eller om Seafile fremover i
                                praksis forbliver en helt selvstændig service.
                            </p>
                            <h4 class="staticpage">29/05-2019: KU i phishing-angreb</h4>
                            <p>
                                KU og KUMail var mål for et større
                                <a href="https://it.ku.dk/driftinfo/">phishing-angreb</a> på det seneste. Tag
                                venligst dine forholdsregler såfremt du var blandt de fuppede og dermed videregav
                                dine login-oplysninger. D.v.s. husk udover naturligvis at skifte dit
                                KU-kodeord også at skifte evt berørte koder du måtte have valgt for dine
                                DeiC Storage SFTP/FTPS/WebDAVS og Seafile services. Ved samme lejlighed vil vi
                                kraftigt anbefale at tilvælge 2-faktor godkendelse på dine DeiC Storage-logins
                                ved at følge 2-Factor Auth guiden på din DeiC Storage Settings side. Du kan vælge 
                                mellem at benytte en af de populære authentictor apps eller benytte den
                                NetIQ app, som KU for nyligt er begyndt at promovere til forskellige services.
                            </p>
                            <h4 class="staticpage">14/05-2019: Problemer med login og adgang</h4>
                            <p>
                                Vi oplevede nye problemer med web-login/adgang her omkring middag. 
                                Denne gang var det så vidt vi har kunnet finde frem til et problem med
                                at vores web-server og Jupyter instanserne endte i en amoktilstand og
                                slugte alle resurser, så man dårligt kunne komme igennem med almindlige
                                web browsere. Efter lidt oprydning, tuning og genstart af services ser
                                det ud til at være løst og tilbage i normal drift.
                            </p>
                            <h4 class="staticpage">10/05-2019: Jupyter nede</h4>
                            <p>
                                Vi oplevede en strømafbrydelse i HPC centeret og Jupyter maskinerne var
                                derfor nede. DAG kom tilbage online efter middag og MODI fulgte ikke så
                                længe efter.
                            </p>
                            <h4 class="staticpage">23/04-2019: Problemer med KU-login og adgang igen</h4>
                            <p>
                                Det ser desværre ud til at problemet med KU-login er vendt tilbage her
                                til formiddag. Vi har kontaktet KUIT og de ser på sagen. Det ser ud til
                                at være tilbage ved normal drift igen siden middag, men vi holder øje med sagen.
                            </p>
                            <h4 class="staticpage">27/03-2019: Problemer med KU-login og adgang</h4>
                            <p>
                                Til formiddag fra omkring kl 10.30 oplevede KU-brugere forskellige
                                problemer med DeiC Storage webadgang. Alle operationer som involverede enten
                                login eller kontrol af aktiv login session tog enormt lang tid, og førte
                                nogle gange ligefrem til timeout og forskellige andre sideindlæsningsfejl.
                                Vi fandt frem til at det var et problem med svartiderne fra KUs OpenID
                                service, som vi benytter til at levere KU-login på DeiC Storage. KUIT kiggede
                                nærmere på det og fik servicen tilbage i normal drift. Alt skulle
                                derfor være fuldt ud funktionelt igen.
                            </p>
                            <h4 class="staticpage">06/02-2019: SIF Effektiv dataadgang</h4>
                            <p>
                                SIF har langt om længe også fået effektiv dataadgang gennem WebDAVS og
                                SFTP. De tilsvarende services har længe været tilgængelige på DeiC Storage, men
                                måtte udbygges til at logge hver eneste adgang og filoperation. For
                                yderligere sikring har vi tilføjet to-faktor godkendelse og gjort det
                                obligatorisk dor dem på SIF. Endelig implementerede vi yderligere
                                restriktioner for de to services på SIF, så brugere kun kan tilgå netop
                                et projekts data af gangen, og kun fra en enkelt IP-adresse. Det er helt
                                i tråd med de eksisterende mekanismer til at sikre mod datalæk på SIFs
                                web-adgang.
                                Bemærk at begge services på SIF derfor kræver et forudgående web-login
                                med to-faktor godkendelse for yderligere sikkerhed. Derudover tilbydes
                                de samme features, så brugere kan benytte SIF som et netværksdrev. Vi
                                henviser til afsnittet om Effektiv datatilgang i brugervejledningen
                                fra <a href="http://sif.ku.dk">SIF forsiden</a> for yderligere information.
                            </p>
                            <h4 class="staticpage">21/01-2019: Vedligehold og planlagt nedetid</h4>
                            <p>
                                Vi har gennemført den planlagte opgradering af DeiC Storage og IDMC frontends
                                med nogle sikkerheds- og generelle fejlrettelser. Arbejdet startede
                                omkring kl 18 og inkluderede genstart af frontends. D.v.s. alle services
                                har været berørt, og der var nogle minutters nedetid.
                            </p> 
                            <h4 class="staticpage">17/01-2019: Web adgang og login fejl</h4>
                            <p>
                                Vi oplevede fejl i forbindelse med login og generel web-adgang mellem kl. 13.00 og 15.00.
                                Dette oprindelige udfald skyldtes fejl i autentificering mod KUs OpenID-tjeneste.
                                Efter dette var overstået var tjeneste stabil i et stykke tid.
                                Dog fulgte et senere udfald, specifikt med fejlende forespørgsler 
                                mod både DeiC Storage og Jupyter for KU OpenID autentificerede brugere.
                                Dette skyltes at gen-autentificerede OpenID brugere der tidligere havde 
                                startet en Jupyter server forårsagede fejlende forespørgsler fra deres gamle
                                Jupyter server både til og fra DeiC Storage. Dette blev løst ved at nulstille de gamle Jupyter-servere. 
                                For nuværende har dette stabiliseret både DeiC Storage og Jupyter, vi vil dog fortsat overvåge
                                situationen i tilfælde af flere fejl skulle følge.
                            </p>
                            <h4 class="staticpage">09/09-2019: Import share links</h4>
                            <p>
                                Efter ønske fra flere brugere har vi tilføjet funktionalitet til nemt at
                                hente data delt på et Share Link ind i dine egne mapper på DeiC Storage/IDMC.
                                Fra Files kan du højreklikke på en folder og vælge Share Links &gt;
                                Import. Indtast/indsæt ID eller URL på det pågældende Share
                                Link og klik Ok for at starte import af al data derfra direkte ind i den
                                valgte folder. I tilfælde af at du kun ønsker at hente en enkel fil
                                eller folder fra Share Linket kan du erstatte '*' i Source Path med
                                navnet på denne før du klikker Ok. Uanset er resultatet at du får din
                                egen kopi af data i den valgte folder.
                            </p>
                            <h4 class="staticpage">08/09-2018: Jupyter vedligehold og planlagt nedetid</h4>
                            <p>
                                Vi opgraderede som planlagt Jupyter servicen på DeiC Storage/IDMC i
                                weekenden. Det indebar nedetid på Jupyter især lørdag, samt kortere
                                udfald og begrænset adgang dertil søndag. Ingen andre services var
                                berørt af arbejdet. Vedligeholdet blev færdigt den 10. september kl 0:10
                                hvorefter Jupyter servicen leveres fra en klynge af 6 fysiske
                                maskiner. De blev ved samme lejlighed opdateret og konfigureret til at
                                tillade op til 8 CPU-kerner og 8 GB hukommelse til hver notebook. Selv i
                                belastede perioder er der altid garanteret 1 kerne og 1 GB hukommelse.
                                Alting ser fint ud og vi forventer normal drift på Jupyter servicen - nu
                                bare med bedre skalering.
                            </p>
                            <h4 class="staticpage">03/09-2018: Vedligehold og planlagt nedetid</h4>
                            <p>
                                Vi opgraderede backend-lageret med nogle fejlrettelser og forberedte
                                tilføjelse af mere diskplads. Arbejdet startede kl 13 og medførte
                                generel nedetid på services indtil kl 14 pga grundlæggende
                                systemopgraderinger. Alt skulle være tilbage i normal drift på
                                DeiC Storage/IDMC. På SIF oplevede vi nogle problemer som krævede lidt ekstra
                                arbejde men den er også tilbage i almindelig drift nu.
                            </p> 
                            <h4 class="staticpage">18/07-2018: Jupyter vedligehold og nedetid</h4>
                            <p>
                                Jupyter-opdateringerne i fredags viste sig mere omfattende end ventet og
                                krævede yderligere indsats i denne uge. Det er nu overstået og servicen er
                                online igen.
                            </p>
                            <h4 class="staticpage">12/07-2018: Jupyter vedligehold og nedetid</h4>
                            <p>
                                Jupyter-servicen vil være helt eller delvis utilgængelig resten af dagen
                                pga vedligehold og opgradering.
                            </p>
                            <h4 class="staticpage">06/07-2018: Understøttelse af 2-faktor autentifikation</h4>
                            <p>
                                Som opfølgning på de nylige sikkerhedstiltag ift IO-services har vi
                                tilføjet 2-faktor autentifikation (2FA) på vores OpenID web logins. I
                                praksis betyder det at brugere nu kan tilføje et ekstra sikkerhedslag,
                                hvorved kontomisbrug bliver markant sværere - selv hvis nogen skulle
                                opsnappe deres KU login og kode (eller deres dedikerede DeiC Storage login når
                                vi taler eksterne brugere). Kort fortalt installerer man som
                                sikkerhedsbevidst bruger en app på sin mobile enhed (smart-phone eller
                                tablet) og skanner en personlig QR sikkerhedskode deri, for at få den
                                til kontinuerligt at levere engangskoder til brug sammen med sit almindelige
                                login. Derved sikres at man <em>kun</em> kan få adgang, hvis man både
                                kender kode og har adgang til enheden. Yderligere detaljer om opsætning
                                og brug findes under dine DeiC Storage Settings -> Web Access.<br/>
                                Vi anbefaler kraftigt at slå 2FA til, hvis man benytter DeiC Storage til at
                                opbevare data kategoriseret som fortrolighedsniveau F2 i den officielle
                                KU dataklassifikation fra 
                                <a href="https://intranet.ku.dk/medarbejderguide/sikkerhed-og-beredskab/IS/Sider/default.aspx">
                                    KUnet</a> (kræver login). Ved samme lejlighed må vi understrege at data
                                kategoriseret som fortrolighedsniveau F1 <em>ikke</em> er tilladt at
                                opbevare på DeiC Storage. Brug i stedet en endnu sikrere og tættere monitoreret
                                løsning som f.eks. <a href="http://sif-www.storage.deic.dk">SIF</a> dertil.<br/>
                                Vi undersøger i øjeblikket muligheden for ligeledes at tilbyde 2FA på vores
                                IO-services. 
                            </p>
                            <h4 class="staticpage">25/06-2018: Strengere password-krav på WebDAVS/SFTP/FTPS</h4>
                            <p>
                                I lyset af det stigende antal angreb som forsøger at knække passwords til
                                vores WebDAVS/SFTP/FTPS-services, har vi yderligere strammet kravene til
                                styrken af passwords. Udover de almindelige KU-krav om otte tegn fra
                                mindst tre tegn-klasser har vi således indført hindring af passwords med
                                almindelige ord eller simple fortløbende tegnsekvenser og møsntre.<br/>
                                Stramningerne trådte i kraft med det samme for password-opsætning og
                                -skift. De vil desuden blive håndhævet for eksisterende passwords når vi
                                næste gang genstarter services.<br/>
                                Såfremt du ikke længere kan logge på de pågældende services kan du gå
                                ind på din DeiC Storage Settings side og prøve at sætte kodeordet igen. Hvis det
                                afvises er du nødt til at finde på et nyt og stærkere kodeord.
                            </p> 
                            <h4 class="staticpage">21/06-2018: SFTP rate-limit</h4>
                            <p>
                                Vi har indført ydeligere automatiske værn mod det stigende antal
                                automatiske forsøg på at gætte SFTP passwords. Det betyder i praksis at
                                vi automatisk midlertidigt lukker for adgang fra IPer der udviser tegn
                                på sådanne angreb. Kontakt os venligst hvis du oplever problemer med
                                login eller overførsler på SFTP-servicen.
                            </p> 
                            <h4 class="staticpage">20/06-2018: Vedligehold og planlagt nedetid</h4>
                            <p>
                                Vi har opgraderet backend-lageret til en nyere version med en stribe
                                fejlrettelser. Derunder bl.a. nogle stabilitets-forbedringer som gerne
                                skulle afhjælpe de periodiske udfald vi har oplevet indenfor det seneste
                                års tid. Arbejdet startede kl 9 og medføre at alle services var nede
                                indtil vi var færdige henved kl 12:30. Alt ser fint ud så langt og vi
                                regner med normal drift igen nu.
                            </p> 
                            <h4 class="staticpage">18/06-2018: Kort udfald</h4>
                            <p>
                                Vi oplevede et problem med frontend til morgen og måtte genstarte alle
                                services. Ved samme lejlighed indskød vi en udestående system genstart. Alt
                                skulle være tilbage i normal drift igen.
                            </p> 
                            <h4 class="staticpage">13/06-2018: Ny DOI-integration</h4>
                            <p>
                                KU-IT har åbnet op for en ny service til Data Object Identifier (DOI)
                                registrering og vi har integreret den med DeiC Storage freeze archives. Det
                                betyder at man nu kan få registreret en kort og permanent reference til
                                sine arkiverede data i DeiC Storage - noget som er blevet et mere udbredt krav
                                fra organisatorer og finansiører ifbm publicering af videnskabelige
                                resultater.
                            </p> 
                            <h4 class="staticpage">19/04-2018: Delvis dataadgang og Seafile nede</h4>
                            <p>
                                Vi har oplevet flere udfald i forbindelsen til vores backend lager, og
                                har måttet genstarte services. Seafile krævede yderligere vedligehold,
                                men det skulle være løst nu.
                            </p>
                            <h4 class="staticpage">17/04-2018: Delvis dataadgang</h4>
                            <p>
                                Vi mistede forbindelsen til en eller flere af vores backend servere, så
                                dataadgangen faldt delvis ud.<br/>
                                Alt er tilbage i almindelig drift, og vi overvåger for at fange evt
                                yderligere problemer.<br/>
                                Vi planlægger desuden en opgradering af glusterfs softwaren, som leverer
                                forbindelsen til backend storage. Det skulle gerne hjælpe på de
                                problemer vi har set på det seneste med udfald.
                            </p>
                            <h4 class="staticpage">06/04-2018: Genindførsel af workgroup workflows</h4>
                            <p>
                                Vi har optimeret Workgroup Workflows servicen så den nu er langt mindre
                                belastende for systemet og har derfor sat den i drift igen. 
                            </p>
                            <h4 class="staticpage">16/03-2018: Delvis dataadgang og loginproblemer</h4>
                            <p>
                                Vi havde et CPU-lockup på en af vores backend servere.
                                <br/>
                                Alt er tilbage i almindelig drift, men vi holder tæt øje med systemerne
                                i tilfælde af at problemerne skulle komme tilbage.<br/>
                            </p>
                            <h4 class="staticpage">15/03-2018: Midlertidig nedtagning af workgroup workflows</h4>
                            <p>
                                Vi har en mistanke om at Workgroup Workflows servicen har haft en
                                negativ indvirkning på de problemer vi oplevede efter diskskiftet
                                forleden. Vi har derfor valgt midlertidigt at slå den fra på
                                DeiC Storage. Såfremt du er afhængig af den til automatisk backup jvf
                                brugervejledningen, kan du enten skifte til den nye Planlagte Opgaver /
                                Schedule Tasks service eller henvende dig til os for en midlertidig
                                erstatning. Planen er at vi sætter workflows i drift igen når vi har
                                fået servicens lagerovervågning optimeret til at være væsentlig mindre
                                resurseintensiv.
                            </p>
                            <h4 class="staticpage">12/03-2018: Delvis dataadgang og loginproblemer</h4>
                            <p>
                                Vi havde et disk-crash i nat og det krævede et fysisk
                                diskskift. Resultatet var delvis datasynlighed, så en stribe filer så ud
                                til at mangle selv om de faktisk var intakte. For brugere hvor centrale
                                loginfiler var ramt, betød det at login blev afvist. Efter at have løst
                                diskproblemerne oplevede vi desværre af flere omgange mistet forbindelse
                                til backend-lageret med samme effekt ift login og delvis dataadgang.<br/>
                                Alt er tilbage i almindelig drift, men vi holder tæt øje med systemerne
                                i tilfælde af at problemerne skulle komme tilbage.<br/>
                            </p>
                            <h4 class="staticpage">11/03-2018: Problemer med dataadgang</h4>
                            <p>
                                Problemerne fra for en uge siden dukkede op igen og vi var nødt til
                                manuelt at intervenere for at få alt tilbage i almindelig drift. Det
                                medførte delvis dataadgang og midlertidige udfald i diverse services.
                            </p>
                            <h4 class="staticpage">05/03-2018: Planlagte opgaver (Schedule Tasks) i beta</h4>
                            <p>
                                Vi har sat den nye funktionalitet til planlagte opgaver i beta-test på
                                DeiC Storage. Med den kan man automatisere opgaver til at køre på givne
                                tidspunkter og på ens vegne. Det kan f.eks. være sådan noget som
                                automatisk oprettelse af backup arkiver hver nat. De nærmere detaljer om
                                brugen findes i brugervejledningen.
                            </p>
                            <h4 class="staticpage">04/03-2018: Problemer med dataadgang og en genstart</h4>
                            <p>
                                Vi oplevede forbindelsesproblemer mellem vores frontend og
                                backend-lageret, hvilket bl.a. førte til fejl ved sletning af mapper. Vi
                                genetablerede forbindelsen og genstartede alle services som løsning, og
                                alt skulle være tilbage i normal drift igen.
                            </p>
                            <h4 class="staticpage">21/02-2018: Seafile opgradering</h4>
                            <p>
                                Vi opgraderede vores Seafile-installation for at få en stribe rettelser
                                ind, inklusive én vi har fået fejlmeldinger om fra jer (tak!).
                                Mere specifikt drejede det sig om at Seafile web-interfacet ikke ville
                                vise filer som enten indeholdt mellemrum eller eksotiske tegn i deres
                                navn eller fulde sti. Alting skulle være tilbage i normal drift nu efter
                                opgradering og tilhørende genstart af servicen.
                            </p>
                            <h4 class="staticpage">13/02-2018: Optimeret SFTP i generel drift</h4>
                            <p>
                                Efter nogle måneder i beta-test på sftp.storage.deic.dk har vi nu integreret den
                                samme nye højtydende SFTP service på den almindelige io.storage.deic.dk adresse. I
                                vores egne tests har vi observeret 10 til 32 gange bedre hastighed over
                                hurtige netværksforbindelser til DeiC Storage. Selv på langsommere forbindelser
                                skulle man dog også gerne opleve tydelige forbedringer.
                            </p>
                            <h4 class="staticpage">12/02-2018: Langsom adgang / nedetid</h4>
                            <p>
                                Alle services var ekstremt langsomme her til morgen pga et diskproblem
                                på frontend-maskinen. I nogle tilfælde førte det til at forbindelser til
                                DeiC Storage fik time-out. Problemet er rettet og alt skulle være tilbage i
                                normal drift igen.<br/>
                                Seafile kunne tilsyneladende ikke lide førnævnte problem og
                                krævede lidt ekstra oprydning. Den er ligeledes tilbage i almindelig
                                drift nu.
                            </p>
                            <h4 class="staticpage">25/01-2018: Vedligehold og kort nedetid</h4>
                            <p>
                                Alle services var kortvarigt nede i forbindelse med en planlagt
                                software-opdatering. Udover en række mindre fejlrettelser dækkede den
                                hovedsageligt optimeringer i forhold til ikke at spilde unødige resurser
                                på automatiserede angreb fra internettet - herunder især forsøg på at
                                gætte kodeord. Alt skulle være tilbage i normal drift igen.
                            </p>
                            <h4 class="staticpage">10/01-2018: Vigtige sikkerhedsopdateringer</h4>
                            <p>
                                Vi færdiggjorde en stribe sikkerhedsopdateringer som følge af 
                                <a href="https://meltdownattack.com/">Meltdown og Spectre</a>
                                sikkerhedshullerne. Det var nødvendigt at genstarte systemer for at få
                                tilhørende kerneopdateringer i drift, og vi havde derfor kortvarigt
                                generel nedetid på alle services.
                            </p>
                            <h4 class="staticpage">10/01-2018: Delvis datasynlighed</h4>
                            <p>
                                Vores aktive frontend-maskine tabte adgang til et antal filer på
                                backend-lageret. Som følge deraf blev en eller flere delte workgroup-mapper
                                midlertidigt usynlige for deltagerne. Ingen data blev tabt og
                                genetablering af forbindelsen til backend-lageret løste problemet.
                            </p>
                            <h4 class="staticpage">02/11-2017: Systemudfald og delvist datatab i Seafile</h4>
                            <p>
                                Vi oplevede et massivt systemudfald p.g.a. en diskfejl samtidig med at
                                en CPU stod af. Resultatet var at store dele af vores systemer var
                                offline det meste af dagen, indtil vi havde fået genetableret og migreret
                                services til en anden maskine. Hvis man skal se noget positivt i det kan
                                det noteres at al almindelig DeiC Storage data overlevede, hvilket bekræfter os
                                i robustheden af vores generelle infrastruktur og design. På den
                                negative side må vi desværre sande at enkelte Seafile-brugere har
                                oplevet at en eller flere af deres filer efter udfaldet automatisk er
                                blevet rullet tilbage til en tidligere version og dermed har overskrevet
                                senere ændringer. Vi er naturligvis meget kede af det gener det har
                                medført, og vi har gjort vores bedste for at hjælpe med at finde frem
                                til det bagvedliggende problem.
                                Vi må understrege at Seafile er en tredjeparts-service, som vi kun
                                tilbyder på DeiC Storage p.g.a. særlig efterspørgsel. Derfor har vi ikke fuld
                                kontrol eller kendskab til hvordan den fungerer internt. Den følger desuden
                                samme backup-politik, d.v.s. <em>du</em> er som bruger selv ansvarlig for
                                eksplicit at lave backup af kritiske data. Dertil kan du f.eks. benytte
                                vores Archive funktion, som kopierer data til bånd på en fjernlokation
                                med henblik på stærk sikring mod netop sådanne datatab. 
                            </p>
                            <h4 class="staticpage">21/09-2017: Optimeret SFTP i beta</h4>
                            <p>
                                Vores nye optimerede SFTP service er sat i beta-test på sftp.storage.deic.dk med
                                samme login-fremgangsmåde som den hidtidige på io.storage.deic.dk. D.v.s. man kan
                                afprøve den på helt samme måde som beskrevet i brugervejledningen, blot
                                med skift af <em>io</em> til <em>sftp</em> i adressen. I vores
                                egne tests har vi observeret 10 til 32 gange bedre hastighed over hurtige
                                netværksforbindelser til DeiC Storage. Selv på langsommere forbindelser skulle man
                                dog også gerne opleve tydelige forbedringer.
                            </p>
                            <h4 class="staticpage">25/07-2017: Særskilt OpenID-login for brugere uden en KU konto </h4>
                            <p>
                                Vi har tilføjet endnu en adgangsløsning for at kunne give folk uden en
                                almindelig KU-konto tilsvarende login til DeiC Storage med brugernavn og
                                kodeord. På den måde er det blevet markant nemmere at koble eksterne
                                samarbejdspartnere på DeiC Storage, sådan som det er beskrevet af det
                                tilhørende punkt i vores <a href="http://www.storage.deic.dk/index.html">FAQ</a> på forsiden. 
                            </p>
                            <h4 class="staticpage">21/04-2017: Skrive-beskyttede delte workgroup-mapper</h4>
                            <p>
                                Infrastrukturen bag de delte workgroup-mapper er ændret så den tillader
                                ejere at skrive-beskytte data. I praksis er det dermed muligt at dele
                                data kun med læse-adgang i en workgroup. Som standard får alle
                                workgroups stadig delte mapper med både læse- og skrive-adgang, men
                                ejere kan slå skrive-adgang fra på administrationssiden for en
                                workgroup. Bemærk at alle workgroups oprettet inden denne dato først
                                skal migreres til den nye struktur for at få samme
                                funktionalitet. Kontakt venligst support omkring sådanne forespørgsler.
                            </p>
                    </div>
                    <p>
                        <a href="http://www.storage.deic.dk">Tilbage til forsiden</a>
                    </p>
                </div>
            </div>
        </div>

        <div id="bottomlogo">
            <div id="bottomlogoleft">
                <div id="support">
                    <img src="/images/icons/help.png" id="supportimage" alt=""/>
                    <div class="supporttext staticpage i18n" lang="en">
                        <p class="supporttitle i18n" lang="en">Support</p>
                        <p class="i18n" lang="en">
                            <a href="https://storage.deic.dk/public/ucph-erda-user-guide.pdf">DeiC Storage
                                User Guide</a><br />Questions about DeiC Storage? <br />Please contact
                            us at <a href="mailto:support@storage.deic.dk">support@storage.deic.dk</a></p>
                    </div>
                    <div class="supporttext staticpage i18n" lang="da">
                        <p class="supporttitle i18n" lang="da">Vejledning</p>
                        <p class="i18n" lang="da"><a href="https://storage.deic.dk/public/ucph-erda-brugervejledning.pdf">DeiC Storage 
                            Brugervejledning</a><br />Spørgsmål om DeiC Storage? <br />Skriv til os på 
                            <a href="mailto:support@storage.deic.dk">support@storage.deic.dk</a></p>
                    </div>
                </div>
            </div>
            <div id="bottomlogoright">
                <div id="privacy">
                    <div class="privacytext staticpage i18n" lang="en">
                        <p class="privacytitle i18n" lang="en">Privacy and Cookies</p>
                        <p class="i18n" lang="en">
                            <a href="/public/site-privacy-policy.pdf">Privacy Policy</a>
                            &amp; <a href="/public/cookie-policy.pdf">Cookie Policy</a>
                        </p>
                    </div>
                    <div class="privacytext staticpage i18n" lang="da">
                        <p class="privacytitle i18n" lang="da">Privatliv og cookies</p>
                        <p class="i18n" lang="da">
                            <a href="/public/site-privacy-policy.pdf">Privacy Policy</a>
                            &amp; <a href="/public/cookie-policy.pdf">Cookie Policy</a>
                        </p>
                    </div>
                </div>
                <div id="copyright">
                    <img src="/images/copyright.png" id="creditsimage" alt=""/>
                    <span id="credits">
                        2003-2021, <a href="https://www.migrid.org">The MiG Project</a>
                    </span>
                </div>
            </div>
        </div>
        <div id="bottomspace">
        </div>

    </body>
</html>
